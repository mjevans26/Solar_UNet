{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extract_Data_GEE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzmS6y3XJGEl"
      },
      "source": [
        "#@title Author: Michael Evans { display-mode: \"form\" }\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbdLwIXWJQMt"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook demonstrates methods used to acquire training data from Google Earth Engine that can be used to train a [fully convolutional neural network (FCNN)](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf), specifically [U-net](https://arxiv.org/abs/1505.04597) using Tensorflow. In this example, we extract 256x256 pixel image chips containing the 3 visible, infrared, and 2 near infrared bands in Sentinel-2 imagery based on [hand-delineated solar array footprints in North Carolina](https://osf.io/ygbwj/). This relatively simple model is a mostly unmodified version of [this example](https://github.com/tensorflow/models/blob/master/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb) from the TensorFlow docs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0eAagvtJi2B"
      },
      "source": [
        "from os.path import join\n",
        "from google.cloud import storage\n",
        "import ee\n",
        "from sys import path\n",
        "import json\n",
        "import numpy as np\n",
        "import rasterio as rio\n",
        "import folium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp7doIHHJnys"
      },
      "source": [
        "## Clone repo containing preprocessing and prediction functions\n",
        "!git clone https://github.com/mjevans26/Satellite_ComputerVision.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VxQa03hJufS"
      },
      "source": [
        "# Load the necessary modules from repo\n",
        "path.append('/content/Satellite_ComputerVision')\n",
        "from utils.clouds import basicQA, maskTOA, maskSR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6JsEWUZJMrx"
      },
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxE4n2_3J4Uz"
      },
      "source": [
        "# Folium setup.\n",
        "\n",
        "print(folium.__version__)\n",
        "\n",
        "# Define a method for displaying Earth Engine image tiles to a folium map.\n",
        "def add_ee_layer(self, ee_image_object, vis_params, name):\n",
        "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
        "  folium.raster_layers.TileLayer(\n",
        "    tiles = map_id_dict['tile_fetcher'].url_format,\n",
        "    attr = \"Map Data Â© Google Earth Engine\",\n",
        "    name = name,\n",
        "    overlay = True,\n",
        "    control = True\n",
        "  ).add_to(self)\n",
        "\n",
        "# Add EE drawing method to folium.\n",
        "folium.Map.add_ee_layer = add_ee_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYwdLS8tKA-Y"
      },
      "source": [
        "# Specify names locations for outputs in Cloud Storage. \n",
        "BUCKET = '{YOUR_GCS BUCKET HERE}'\n",
        "BUCKET_PATH = join('gs://', BUCKET)\n",
        "\n",
        "FOLDER = 'NC_solar'\n",
        "PRED_BASE = 'data/predict'\n",
        "TRAIN_BASE = 'data/training'\n",
        "EVAL_BASE = 'data/eval'\n",
        "\n",
        "# Specify inputs (Sentinel bands) to the model and the response variable.\n",
        "opticalBands = ['B2', 'B3', 'B4']\n",
        "thermalBands = ['B8', 'B11', 'B12']\n",
        "\n",
        "BANDS = opticalBands + thermalBands\n",
        "RESPONSE = 'landcover'\n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "SCENEID = 'SENSING_ORBIT_NUMBER'\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 256\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-5l_EfywDvK"
      },
      "source": [
        "# Imagery\n",
        "\n",
        "Access and process the imagery to use for predictor variables using Google Earth Engine.  This is a three-month, cloud-free, Sentinel-2 composite corresponding to the latest date from which we have confirmed training data.  Display it in the notebook for a sanity check."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btEC3dluJfGq"
      },
      "source": [
        "# Use Sentinel-2 surface reflectance data.\n",
        "S2 = ee.ImageCollection(\"COPERNICUS/S2\")\n",
        "# Grab a feature corresponding to our study area - North Carolina\n",
        "states = ee.FeatureCollection(\"TIGER/2016/States\")\n",
        "nc = states.filter(ee.Filter.eq('NAME', 'North Carolina')).geometry().buffer(2500)\n",
        "begin = '2019-01-01'\n",
        "end = '2020-03-01'\n",
        "\n",
        "# The image input collection is cloud-masked.\n",
        "filtered = S2.filterDate(begin, end)\\\n",
        ".filterBounds(nc)\\\n",
        ".filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
        "\n",
        "\n",
        "# Create a simple median composite to visualize\n",
        "winter = filtered.filterDate('2019-12-01', '2020-02-28').map(basicQA).median().select(BANDS).clip(nc)\n",
        "spring = filtered.filterDate('2019-03-01', '2019-05-31').map(basicQA).median().select(BANDS).clip(nc)\n",
        "summer = filtered.filterDate('2019-06-01', '2019-08-31').map(basicQA).median().select(BANDS).clip(nc)\n",
        "fall = filtered.filterDate('2019-09-01', '2019-11-30').map(basicQA).median().select(BANDS).clip(nc)\n",
        "\n",
        "# Use folium to visualize the imagery.\n",
        "#mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})\n",
        "rgbParams = {'bands': ['B4', 'B3', 'B2'],\n",
        "             'min': 0,\n",
        "             'max': 0.3}\n",
        "\n",
        "nirParams = {'bands': ['B8', 'B11', 'B12'],\n",
        "             'min': 0,\n",
        "             'max': 0.3}\n",
        "\n",
        "map = folium.Map(location=[35.402, -78.376])\n",
        "map.add_ee_layer(spring, rgbParams, 'Color')\n",
        "map.add_ee_layer(spring, nirParams, 'Thermal')\n",
        "\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpCLxJLVwTHw"
      },
      "source": [
        "Prepare the response variable.  This is the footprints of ground mounted solar arrays as of 2019. These polygons have been loaded into GEE as a FeatureCollection asset, and coded into a background class [0] and a target class [1].Display on the map to verify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS6FWd90wSDW"
      },
      "source": [
        "def set_landcover(ft):\n",
        "  \"\"\"\n",
        "  Add a property to a feature and set it to 1\n",
        "  Parameters:\n",
        "    ft (ee.Feature): feature to have property added\n",
        "  Returns:\n",
        "    ee.Feature: input feature with 'label' property set to 1\n",
        "  \"\"\"\n",
        "  return ft.set('landcover', 1)\n",
        "\n",
        "# Get solar footprints data from our GEE Asset\n",
        "NC_solar_footprints = ee.FeatureCollection(\"users/defendersofwildlifeGIS/NC/NC_solar_footprints\")\n",
        "# Label each polygon with property 'label' equal to 1\n",
        "NC_solar_footprints = NC_solar_footprints.map(set_landcover)\n",
        "# Create an image with all pixels equal to 0\n",
        "blankimg = ee.Image.constant(0)\n",
        "# Convert solar footprints to an image (band value will be 1 based on 'label')\n",
        "solar_footprint = NC_solar_footprints.reduceToImage(['landcover'], ee.Reducer.first())\n",
        "# Convert pixels of blank image to 1 where the values of the footprint image are 1\n",
        "# and rename to 'landcover'\n",
        "labelimg = blankimg.where(solar_footprint, solar_footprint).rename('landcover')\n",
        "\n",
        "solarParams = {'bands': 'landcover', 'min':0, 'max': 1}\n",
        "\n",
        "map = folium.Map(location = [35.402, -78.376])\n",
        "map.add_ee_layer(labelimg,  solarParams, 'Solar footprint')\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjxyM6Lswn0n"
      },
      "source": [
        "Use some pre-made geometries to sample the stack in strategic locations.  We constrain sampling to occur within 10km of mapped solar arrays. Because our target features are small and sparse, relative to the landscape, we also guide sampling based on their centroids to ensure that we get training data for solar arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-xg0yQXwmTJ"
      },
      "source": [
        "def buff(ft):\n",
        "  return ft.buffer(10000)\n",
        "\n",
        "def centroid(ft):\n",
        "  return ft.centroid()\n",
        "\n",
        "centroids = NC_solar_footprints.map(centroid)\n",
        "studyArea = NC_solar_footprints.map(buff).union()\n",
        "studyImage = ee.Image(0).byte().paint(studyArea, 1)\n",
        "studyImage = studyImage.updateMask(studyImage)\n",
        "centroids = centroids.randomColumn('random')\n",
        "\n",
        "aoiParams = {'min':0, 'max': 1, 'palette': ['red']}\n",
        "map = folium.Map(location=[35.402, -78.376], zoom_start=8)\n",
        "map.add_ee_layer(studyImage, aoiParams, 'Sampling area')\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_Ts4CAYwhv1"
      },
      "source": [
        "# Sampling\n",
        "\n",
        "If the mapped data look reasonable, we use a 2-stage approach to sample 256-256 pixel image 'chips' for use in model training.\n",
        "1.) sample from the centroid of each polygon to create 'positive' examples.\n",
        "2.) sample the image at random points to generate 'negative' examples.\n",
        "\n",
        "To sample chips we create an array image in which each pixel contains a nested list of the surrounding 256x256 pixel values. We can sample this array image at points, to get all the pixels in a 256x256 neighborhood at each point.  It's worth noting that to build the training and testing data for the FCNN, you export a single TFRecord file that contains patches of pixel values in each record.  You do NOT need to export each training/testing patch to a different image.  Since each record potentially contains a lot of data (especially with big patches or many input bands), some manual sharding of the computation is necessary to avoid the `computed value too large` error.  Specifically, the following code takes multiple (smaller) samples within each geometry, merging the results to get a single export."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8me8XqzzEWP"
      },
      "source": [
        "def make_array_image(features, labels, aoi):\n",
        "  \"\"\"Combine predictor bands and label band into an array image\n",
        "  Parameters:\n",
        "    features (ee.Image): image containing bands to be used as predictor variables in model\n",
        "    labels (ee.Image): binary[0,1], single-band image indicating presence (1) and absence (0) of target features\n",
        "    aoi (ee.Geometry): bounds\n",
        "  Return:\n",
        "    ee.Image: array image\n",
        "  \"\"\"\n",
        "  \n",
        "  featureStack = ee.Image.cat([features, labels]).clip(aoi)\n",
        "\n",
        "  ls = ee.List.repeat(1, KERNEL_SIZE)\n",
        "  lists = ee.List.repeat(ls, KERNEL_SIZE)\n",
        "  kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "  arrays = featureStack.neighborhoodToArray(kernel)\n",
        "  return arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD62TGagw3Im"
      },
      "source": [
        "First we'll collect image patches from the centroids of known solar array locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT4YxEoMw0qK"
      },
      "source": [
        "# Add a random column to the centroids\n",
        "S = centroids.size().getInfo()\n",
        "centroidList = centroids.toList(S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn-RyVA3xDEi"
      },
      "source": [
        "#@title Centroids slicing\n",
        "# Get samples from delineated features using slice() on a feature collection\n",
        "\n",
        "x = 0\n",
        "\n",
        "# set the number of samples to include in a single export. may need to experiment with this parameter to avoid memory issues\n",
        "n = 25\n",
        "\n",
        "while x < S:\n",
        "  # select a subset of 25 centroids\n",
        "  subset = ee.FeatureCollection(centroidList.slice(x, x+n))\n",
        "  # buffer those\n",
        "  studyArea = subset.map(buff).union()\n",
        "  arrays = make_array_image(fall.select(BANDS), labelimg.select(RESPONSE), studyArea)\n",
        "  sample = arrays.sampleRegions(\n",
        "      collection = subset.geometry(),\n",
        "      scale = 10,\n",
        "      tileScale = 12\n",
        "  )\n",
        "  x += n\n",
        "                                  \n",
        "  # assign a random number to samples and create a 70/30 train/test split\n",
        "  sample = sample.randomColumn('random')\n",
        "  training = sample.filter(ee.Filter.gte('random', 0.3))\n",
        "  testing = sample.filter(ee.Filter.lt('random', 0.3))\n",
        "\n",
        "  desc = 'UNET_' + str(KERNEL_SIZE) + '_centFall' + str(x)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = training,\n",
        "    description = desc, \n",
        "    bucket = BUCKET, \n",
        "    fileNamePrefix = join(FOLDER, TRAIN_BASE, desc),\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  desc = 'UNET_' + str(KERNEL_SIZE) + '_centFall' + str(x)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = testing,\n",
        "    description = desc, \n",
        "    bucket = BUCKET, \n",
        "    fileNamePrefix = join(FOLDER, EVAL_BASE, desc),\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwHW6fKTxVk7"
      },
      "source": [
        "Generate random samples within the buffered area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIv_-Mc2xRZ8"
      },
      "source": [
        "#@title Random sampling\n",
        "\n",
        "# Define sample sizes for shards and chunks. \n",
        "# These numbers determined experimentally.\n",
        "n = 30 # Number of shards in each chunk.\n",
        "N = 300 # Total sample size in each chunk.\n",
        "C = 2# Number of chunks\n",
        "\n",
        "iterator = iter(range(N*C))\n",
        "arrays = make_array_image(fall.select(BANDS),\n",
        "                          labelimg.select(RESPONSE),\n",
        "                          studyArea)\n",
        "for c in range(C):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "\n",
        "  for i in range(n):\n",
        "    seed = next(iterator)\n",
        "    sample = arrays.sample(\n",
        "        region = studyArea,\n",
        "        scale = 10,\n",
        "        numPixels = N/n,\n",
        "        seed = seed,\n",
        "        tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "\n",
        "  #divide samples into training and evaluation data\n",
        "  geomSample = geomSample.randomColumn('random')\n",
        "  training = geomSample.filter(ee.Filter.gte('random', 0.3))\n",
        "  testing = geomSample.filter(ee.Filter.lt('random', 0.3))\n",
        "\n",
        "  desc = 'UNET_' + str(KERNEL_SIZE) + '_randFall'+str(c)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = training,\n",
        "    description = desc, \n",
        "    bucket = BUCKET, \n",
        "    fileNamePrefix = join(FOLDER, TRAIN_BASE, desc),\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  desc = 'UNET_' + str(KERNEL_SIZE) + '_randFall' + str(c)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = testing,\n",
        "    description = desc, \n",
        "    bucket = BUCKET, \n",
        "    fileNamePrefix = join(FOLDER, EVAL_BASE, desc),\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}